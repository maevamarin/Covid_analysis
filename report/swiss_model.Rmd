# Modeling the spread of COVID-19 in a single country

## The logistic model in R

Using the filtered dataset, we study the spread of COVID-19 with the logistic model.
Letting $C_{i}(t) = C_{d_{0,i} + t,i}$, the model for country $i$ can be expressed as:

\[
  C_{i}(t) = \frac{K_{i} \cdot C_{i}(0)}{C_{i}(0) + (K_{i}-C_{i}(0)) \, \exp(-R_{i}\,t)}
\]

The goal is to find the final number of cases $K_{i}$ and the infection rate $R_{i}$. We implement this in R using the following function:

```{r, echo = TRUE}
# here, we assume that data is a data frame with two variables
#  - t: the number of event days
#  - confirmed: the number of confirmed cases at time t
logistic_model <- function(data) {
  data <- data %>% arrange(t)
  C_0 <- data$confirmed[1]
  C_max <- data$confirmed[nrow(data)]
  nls(
    formula = confirmed ~ K / (1 + ((K - C_0) / C_0) * exp(-R * t)),
    data = data,
    start = list(K = 2 * C_max, R = 0.5),
    control = nls.control(minFactor = 1e-6, maxiter = 100)
  )
}
```

Notice:

* We use the nonlinear least square method `stats::nls` to fit the unknown parameters.
* In R, the formula above is `confirmed ~ K / (1 + ((K - C_0)/C_0) * exp(-R * t))`.
* As starting point $(K_0, R_0)$ for the optimiser, we set $R_0 = 0.5$ and $K_0 = 2 \, C(t^*)$, where $t^*$ is the latest information about accumulated confirmed cases.
* We further set the `control` argument as `nls.control(minFactor = 1e-6, maxiter = 100)`.

## The logistic model applied to data from Switzerland

From `covid19_data_filtered`, extract a table `covid19_ch` which corresponds to data for Switzerland.
Then:

* Use the function above to fit the logistic model for Switzerland
* Describe its output (fitted parameters, `broom::tidy()` might be useful here)
* Discuss the goodness-of-fit.
* Plot the fitted curve, as well as observed data points. 
* Present the predictions of the model. What is the estimated final size of the epidemic and infection rate in Switzerland?



 
 As explained above, K is the final number of cases confirmed of convid-19 in Switzerland and R the death rate associated to this virus in this country.

 The table \@ref(tab:table3) showa that the final estimation for K 21'500 cases with a standard deviation of 373 cases. The p-value of 2.909e-27 is largely under 0.1%, which makes our model significant at a level of 99.9%. 
Concerning R, we get an 24.60% of death rate with a standard error of 0.00316. The p-value associated is significant at 99.9%.


```{r table3, warning=FALSE, message=FALSE, echo = FALSE}
covid19_ch <- covid19_data_filtered %>% filter(country=="Switzerland")
broom::tidy(logistic_model(covid19_ch))  %>%
     kable(
    caption = "K = confirmed case, R = Infesction rate"
       ) %>%
  kable_styling(
    bootstrap_options = "striped")
```


The model stops at the day 25.
In the table \@ref(tab:table4), we observe that the total number of cases is 20'162.34, we thus expect to have 20'163 confirmed cases of coronavirus after 25 days. The data for Switzerland reports 21'100 confirmed cases of convid-19 for the 25th day. The model is quite reliable, even if the prediction is under the observed value. In the medical field, we prefer overestimate than underestimate, because the risk associated to overestimation is lower than the inverse. We would have preferred a higher number than 21'100. 

```{r table4, warning=FALSE, message=FALSE, echo = FALSE}
augment_model <-broom::augment(logistic_model(covid19_ch))
broom::augment(logistic_model(covid19_ch)) %>% print(n=10) %>%
     kable(
    caption = "Presentation of the prediction"
       ) %>%
  kable_styling(
    bootstrap_options = "striped")
```


However, the fitted curves represents well the observed line, as we notice in the Figure \@ref(fig:fig-12). We note some slight differences what matches the residuals' plot \@ref(fig:fig-13), presenting their increasing variance through time. According to the trend of the fitted curve, we might expect that the number of cases qould grow at a lowest rates than between th 5th and 13th day, where the slope is slanted. We conclude that the model represents well the evolution of cases on the time span of the data set, but can't be used for predicting number of cases among this time laps, or at the expense of goodness of fit: it would underestimate the predicted values.

```{r fig-12, fig.cap="Plot of fitted vs observed values", out.width="80%", fig.asp=.75,fig.align='center', warning=FALSE, message=FALSE, echo = FALSE}
augment_model %>% ggplot() +
  geom_line(aes(x=t, y= confirmed, col="Observed")) +
  geom_line(aes(x=t, y= .fitted, col="Fitted" )) +
  labs(title = "Well goodness-of fit", subtitle = "Between the observed and fitted value", x= "Time period",y= "Confirmed people", col= "Model")
```



Once our logistic model applied, we consider the residuals given by the difference between fitted abd observed values.
The figure \@ref(fig:fig-13) points out the residuals' variance increasing over time. It means that our model fits less and less well the observed data.
A good model has normally no pattern in its residuals, which is not the case here. If we decide to use a model showing a similar pattern, the person must be aware that those model is not well fitted to the data, even if some insight could be caught by it. We will use the our model to pursue our analysis, so we have to remind its limits, somehow stronger than other models with a better goodness-of-fit-

A last information is that the residuals have this pendulum trend which increases overtime. It assumes that the error margin would be greater over time.

```{r fig-13, fig.cap="Residuals plot", out.width="80%", fig.asp=.75,fig.align='center', warning=FALSE, message=FALSE, echo = FALSE}

augment_model %>% 
  ggplot(aes(x=t,y=.resid)) + 
  geom_hline(yintercept = 0, colour = "bisque3", size= 1) + 
  geom_line() + 
  labs(
    x = "Day", 
    y = "Residuals",
    title = "The variance of the model's residuals increases by time",
    subtitle = "Residuals's variation for Switzerland on 25 days",
    caption = "covid19_ch data")

```